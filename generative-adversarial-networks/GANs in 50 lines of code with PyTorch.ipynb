{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN example with PyTorch\n",
    "This is intended to be a concise example of Generative Adversarial Networks, therefore no deep explanation is given.\n",
    "\n",
    "In GAN architecture, there are two Neural Networks competing against each other. The first is called generator (we'll give it the $G$ label) and it simply generate new data. The second is a discriminative network (we'll label it as $D$) that is a common classificator.\n",
    "\n",
    "The generator $G$ goal is to fool the discriminator $D$, trying to make it think the generated data are real. The discriminator will try to classify incoming data as real or fake. This is how the $G$ and $D$ compete. \n",
    "\n",
    "Code taken from [this article](https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** First we create the function to generate our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Next we prepare function that creates the input that goes to the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Next, we create our generator (which is a standard FeedFoward network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `nn.Linear` is a linear layer from PyTorch that applies a linear transformation in the data: $y = xA^T + b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines the generator network, G.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.f(self.map1(x))\n",
    "        x = self.f(self.map2(x))\n",
    "        return self.f(self.map3(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Now we create our discriminator (also, a FeedFoward network). Note that the code is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines the discriminator network, D.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.f(self.map1(x))\n",
    "        x = self.f(self.map2(x))\n",
    "        return self.f(self.map3(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Finally, we create the training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the loop, we need to set some things up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moments(d):\n",
    "    \"\"\"\n",
    "    Return the first 4 moments of the data provided\n",
    "    For more information about moments check the link:\n",
    "    https://www.thoughtco.com/what-are-moments-in-statistics-3126234\n",
    "    \"\"\"\n",
    "    \n",
    "    mean = torch.mean(d)\n",
    "    diffs = d - mean\n",
    "    var = torch.mean(torch.pow(diffs, 2.0))\n",
    "    std = torch.pow(var, 0.5)\n",
    "    zscores = diffs / std\n",
    "    skews = torch.mean(torch.pow(zscores, 3.0))\n",
    "    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  # excess kurtosis, should be 0 for Gaussian\n",
    "    final = torch.cat((mean.reshape(1,), std.reshape(1,), skews.reshape(1,), kurtoses.reshape(1,)))\n",
    "    return final\n",
    "\n",
    "def stats(d):\n",
    "    \"\"\"\n",
    "    Returns mean and stdev of given data vector \n",
    "    \"\"\"\n",
    "    \n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def extract(v):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "# Data params\n",
    "data_mean = 4\n",
    "data_stdev = 1.25\n",
    "\n",
    "g_input_size = 1                # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 5               # Generator hidden layers size\n",
    "g_output_size = 1               # Size of generated output vector\n",
    "\n",
    "d_input_size = 500              # Input size coming into discriminator\n",
    "d_hidden_size = 10              # Discriminator hidden layers size\n",
    "d_output_size = 1               # Single dimension for 'real' vs. 'fake' classification\n",
    "\n",
    "epochs = 5000                   # Training epochs\n",
    "d_steps = 20                    # Train steps for D\n",
    "g_steps = 20                    # Train steps for G\n",
    "\n",
    "minibatch_size = d_input_size   #\n",
    "\n",
    "# Get samplers\n",
    "g_sampler = get_generator_input_sampler()\n",
    "d_sampler = get_distribution_sampler(data_mean, data_stdev)\n",
    "\n",
    "# Instantiates generator\n",
    "G = Generator(input_size=g_input_size,\n",
    "                  hidden_size=g_hidden_size,\n",
    "                  output_size=g_output_size,\n",
    "                  f=torch.tanh)\n",
    "\n",
    "# Instantiates discriminator\n",
    "D = Discriminator(input_size=d_input_size,\n",
    "                  hidden_size=d_hidden_size,\n",
    "                  output_size=d_output_size,\n",
    "                  f=torch.sigmoid)\n",
    "\n",
    "d_learning_rate = 1e-3          # D learning rate\n",
    "g_learning_rate = 1e-3          # G learning rate\n",
    "sgd_momentum = 0.9              #\n",
    "    \n",
    "# Define optimizers for D and G\n",
    "d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
    "g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)\n",
    "\n",
    "# Define the cost function as the\n",
    "# binary cross-entropy function.\n",
    "cost = nn.BCELoss()\n",
    "\n",
    "dfe, dre, ge = 0, 0, 0\n",
    "d_real_data, d_fake_data, g_fake_data = None, None, None\n",
    "\n",
    "print_interval = 100            # defines a regular interval to print info and stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we perform the actually training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D (0.20092250406742096 real_err, 0.2159106582403183 fake_err) G (0.21251614391803741 err); Real Dist ([4.00015239238739, 1.2839091444746191]),  Fake Dist ([0.1546692524254322, 0.058713997862042185]) \n",
      "Epoch 100: D (0.0032095503993332386 real_err, 0.004487195517867804 fake_err) G (0.004470251966267824 err); Real Dist ([4.075904984116554, 1.2635852427961882]),  Fake Dist ([0.3809716682434082, 0.04731612615002367]) \n",
      "Epoch 200: D (0.0015005397144705057 real_err, 0.0020566259045153856 fake_err) G (0.002046412555500865 err); Real Dist ([3.996270431637764, 1.1868401026613342]),  Fake Dist ([0.44569210189580916, 0.04370137079643329]) \n",
      "Epoch 300: D (0.000965942395851016 real_err, 0.0013009423855692148 fake_err) G (0.0013062540674582124 err); Real Dist ([3.967964541912079, 1.2266390775962484]),  Fake Dist ([0.47950993180274964, 0.0407742171730421]) \n",
      "Epoch 400: D (0.0007097855559550226 real_err, 0.0009428533958271146 fake_err) G (0.0009446432231925428 err); Real Dist ([4.01204094479233, 1.3248732223050217]),  Fake Dist ([0.5034393171072006, 0.04089205034517585]) \n",
      "Epoch 500: D (0.000559665379114449 real_err, 0.0007334656547755003 fake_err) G (0.0007337042479775846 err); Real Dist ([3.9672477271556854, 1.276769898593561]),  Fake Dist ([0.5208179486989974, 0.0397598053855411]) \n",
      "Epoch 600: D (0.0004613271448761225 real_err, 0.000599921855609864 fake_err) G (0.0006003989838063717 err); Real Dist ([4.0012576061487195, 1.2142638493728644]),  Fake Dist ([0.5306803714036942, 0.039743156049508344]) \n",
      "Epoch 700: D (0.00039173883851617575 real_err, 0.0005050980835221708 fake_err) G (0.0005041439435444772 err); Real Dist ([4.067655187726021, 1.2335079707696397]),  Fake Dist ([0.5422387738823891, 0.03830282876293922]) \n",
      "Epoch 800: D (0.0003401619615033269 real_err, 0.0004358645237516612 fake_err) G (0.0004370571405161172 err); Real Dist ([4.004700552880764, 1.2632699228590545]),  Fake Dist ([0.5483983959555626, 0.0352599266838062]) \n",
      "Epoch 900: D (0.00030045254970900714 real_err, 0.0003826158063020557 fake_err) G (0.00038273504469543695 err); Real Dist ([4.070414484173059, 1.2567239190065012]),  Fake Dist ([0.5606196832060814, 0.03621689663234821]) \n",
      "Epoch 1000: D (0.0002690319379325956 real_err, 0.0003413544618524611 fake_err) G (0.00034147370024584234 err); Real Dist ([4.000198600828647, 1.2456442797387866]),  Fake Dist ([0.5622874462008476, 0.03689130961837992]) \n",
      "Epoch 1100: D (0.0002432761393720284 real_err, 0.00030736878397874534 fake_err) G (0.0003072495455853641 err); Real Dist ([4.011771926641464, 1.3092857428049878]),  Fake Dist ([0.5677985877990722, 0.03476108466046139]) \n",
      "Epoch 1200: D (0.00022205195273272693 real_err, 0.0002797637425828725 fake_err) G (0.0002792867599055171 err); Real Dist ([4.041045251011848, 1.2045583995930786]),  Fake Dist ([0.5716382787227631, 0.03579123349101568]) \n",
      "Epoch 1300: D (0.00020428598509170115 real_err, 0.0002556770050432533 fake_err) G (0.0002547230978962034 err); Real Dist ([3.908941412985325, 1.1989832447617188]),  Fake Dist ([0.5760017951726913, 0.03538545403351573]) \n",
      "Epoch 1400: D (0.0001890241983346641 real_err, 0.00023588340263813734 fake_err) G (0.00023624110326636583 err); Real Dist ([4.03993887603283, 1.2032921267872068]),  Fake Dist ([0.5804993362426758, 0.035052259147635066]) \n",
      "Epoch 1500: D (0.00017578955157659948 real_err, 0.00021907106565777212 fake_err) G (0.00021835564984939992 err); Real Dist ([3.9583916330412032, 1.2648444849201197]),  Fake Dist ([0.5835851519107819, 0.03501878795443821]) \n",
      "Epoch 1600: D (0.0001644031290197745 real_err, 0.00020392828446347266 fake_err) G (0.00020404750830493867 err); Real Dist ([4.031643386721611, 1.2158601749660691]),  Fake Dist ([0.5895993478298187, 0.034225418018666784]) \n",
      "Epoch 1700: D (0.00015426872414536774 real_err, 0.00019152805907651782 fake_err) G (0.00019093191076535732 err); Real Dist ([4.039185257807374, 1.2441119903775666]),  Fake Dist ([0.5906382268667221, 0.03488155935118586]) \n",
      "Epoch 1800: D (0.00014544591249432415 real_err, 0.00017948569438885897 fake_err) G (0.00017984338046517223 err); Real Dist ([3.9856768120229242, 1.2646745406760789]),  Fake Dist ([0.5939540786743164, 0.0334479164819334]) \n",
      "Epoch 1900: D (0.000137457755045034 real_err, 0.00016881460032891482 fake_err) G (0.00016929152479860932 err); Real Dist ([3.985863631814718, 1.252624945466217]),  Fake Dist ([0.5974598586559295, 0.033573937089827754]) \n",
      "Epoch 2000: D (0.00013030423724558204 real_err, 0.00015987243386916816 fake_err) G (0.00015987243386916816 err); Real Dist ([3.992961655795574, 1.3038356575840502]),  Fake Dist ([0.5993241876363754, 0.033280151900501015]) \n",
      "Epoch 2100: D (0.00012386612070258707 real_err, 0.00015176493616309017 fake_err) G (0.00015224184608086944 err); Real Dist ([3.976748329281807, 1.1975645183520685]),  Fake Dist ([0.599663230895996, 0.03305471658319226]) \n",
      "Epoch 2200: D (0.00011802415974671021 real_err, 0.00014449209265876561 fake_err) G (0.0001443728688172996 err); Real Dist ([4.040356777466833, 1.3089251374401754]),  Fake Dist ([0.6037411268949509, 0.033446982702984566]) \n",
      "Epoch 2300: D (0.00011265912326052785 real_err, 0.000137696202727966 fake_err) G (0.00013781544112134725 err); Real Dist ([4.018781594634056, 1.2241750194425485]),  Fake Dist ([0.6051322544813156, 0.03275859155338537]) \n",
      "Epoch 2400: D (0.00010777100396808237 real_err, 0.00013161571405362338 fake_err) G (0.00013149649021215737 err); Real Dist ([4.0300397388935085, 1.2297678416857054]),  Fake Dist ([0.6065596123933792, 0.03235140080323594]) \n",
      "Epoch 2500: D (0.00010324057075195014 real_err, 0.00012601216440089047 fake_err) G (0.00012601216440089047 err); Real Dist ([3.979679751992226, 1.189689709997855]),  Fake Dist ([0.6083441734313965, 0.032976611688118745]) \n",
      "Epoch 2600: D (9.918704745359719e-05 real_err, 0.00012017018161714077 fake_err) G (0.00012088552466593683 err); Real Dist ([3.971322305679321, 1.3187313559088338]),  Fake Dist ([0.61373557305336, 0.0314867008242625]) \n",
      "Epoch 2700: D (9.537197911413386e-05 real_err, 0.00011599736899370328 fake_err) G (0.00011563969746930525 err); Real Dist ([4.02830472099781, 1.2537370745247278]),  Fake Dist ([0.6113719083070756, 0.032679603505776804]) \n",
      "Epoch 2800: D (9.179536573356017e-05 real_err, 0.00011110922787338495 fake_err) G (0.00011122845171485096 err); Real Dist ([3.8380447491109373, 1.1514753314749817]),  Fake Dist ([0.6155081485509872, 0.03153716498511137]) \n",
      "Epoch 2900: D (8.857642387738451e-05 real_err, 0.00010717489203670993 fake_err) G (0.00010693645162973553 err); Real Dist ([4.0703190327622, 1.2607568468063568]),  Fake Dist ([0.6147168296575546, 0.031084305362292564]) \n",
      "Epoch 3000: D (8.547671313863248e-05 real_err, 0.00010335979459341615 fake_err) G (0.00010335979459341615 err); Real Dist ([3.978159533381462, 1.2580469301992032]),  Fake Dist ([0.6168371684551239, 0.03189649605270015]) \n",
      "Epoch 3100: D (8.261545008281246e-05 real_err, 9.966393554350361e-05 fake_err) G (0.00010002159251598641 err); Real Dist ([4.053976585388184, 1.2148399816651883]),  Fake Dist ([0.6177096707820893, 0.032644743356481085]) \n",
      "Epoch 3200: D (7.999263470992446e-05 real_err, 9.65641884249635e-05 fake_err) G (9.64449645834975e-05 err); Real Dist ([4.012400505900383, 1.2484188763479005]),  Fake Dist ([0.6153519561290741, 0.032247573768618976]) \n",
      "Epoch 3300: D (7.748904317850247e-05 real_err, 9.346444858238101e-05 fake_err) G (9.334523201687261e-05 err); Real Dist ([4.0578023835497445, 1.2360175297403526]),  Fake Dist ([0.6176354775428772, 0.03205440325421766]) \n",
      "Epoch 3400: D (7.510467548854649e-05 real_err, 9.024550672620535e-05 fake_err) G (9.024550672620535e-05 err); Real Dist ([4.0652925201654435, 1.1816518504213758]),  Fake Dist ([0.620644762635231, 0.03158913597465273]) \n",
      "Epoch 3500: D (7.283953164005652e-05 real_err, 8.75034456839785e-05 fake_err) G (8.75034456839785e-05 err); Real Dist ([4.0060693975687025, 1.1960175706210652]),  Fake Dist ([0.6213953971862793, 0.031564464982027925]) \n",
      "Epoch 3600: D (7.081282819854096e-05 real_err, 8.488061575917527e-05 fake_err) G (8.511905616614968e-05 err); Real Dist ([3.9839472241401674, 1.263874656477678]),  Fake Dist ([0.621057270526886, 0.03216551041003752]) \n",
      "Epoch 3700: D (6.878612475702539e-05 real_err, 8.237700967583805e-05 fake_err) G (8.249623351730406e-05 err); Real Dist ([4.05744536960125, 1.2168659998114195]),  Fake Dist ([0.622445640206337, 0.032037824413032864]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3800: D (6.687864515697584e-05 real_err, 8.023106784094125e-05 fake_err) G (8.023106784094125e-05 err); Real Dist ([4.004149026274681, 1.3157129248810608]),  Fake Dist ([0.6236022375822067, 0.03168649866891332]) \n",
      "Epoch 3900: D (6.520960596390069e-05 real_err, 7.820434984751046e-05 fake_err) G (7.820434984751046e-05 err); Real Dist ([4.076516931891441, 1.251320375266635]),  Fake Dist ([0.6250120311975479, 0.03193548149316131]) \n",
      "Epoch 4000: D (6.342135020531714e-05 real_err, 7.605842256452888e-05 fake_err) G (7.593919872306287e-05 err); Real Dist ([4.008521069377661, 1.2833013158426176]),  Fake Dist ([0.6237312965393066, 0.03171582538349023]) \n",
      "Epoch 4100: D (6.1871534853708e-05 real_err, 7.39124880055897e-05 fake_err) G (7.41509284125641e-05 err); Real Dist ([4.022280661225319, 1.2325043479738893]),  Fake Dist ([0.6261633501052857, 0.031325350940422]) \n",
      "Epoch 4200: D (6.032171950209886e-05 real_err, 7.212421769509092e-05 fake_err) G (7.224344153655693e-05 err); Real Dist ([4.016529090523719, 1.168535607848063]),  Fake Dist ([0.6280526033639908, 0.031229394314286608]) \n",
      "Epoch 4300: D (5.889112435397692e-05 real_err, 7.009752152953297e-05 fake_err) G (7.045517122605816e-05 err); Real Dist ([3.9979546337127685, 1.2813439865960596]),  Fake Dist ([0.6312583512067795, 0.0306884395353617]) \n",
      "Epoch 4400: D (5.746052920585498e-05 real_err, 6.85476916260086e-05 fake_err) G (6.85476916260086e-05 err); Real Dist ([4.070041207790375, 1.22526297395133]),  Fake Dist ([0.6302944099903107, 0.030658823937426055]) \n",
      "Epoch 4500: D (5.614915062324144e-05 real_err, 6.699786172248423e-05 fake_err) G (6.711708556395024e-05 err); Real Dist ([3.9715832611024378, 1.1914087407355505]),  Fake Dist ([0.6293482205867768, 0.03100320107637711]) \n",
      "Epoch 4600: D (5.49569922441151e-05 real_err, 6.556725566042587e-05 fake_err) G (6.532882252940908e-05 err); Real Dist ([4.042671125710011, 1.2441610461500716]),  Fake Dist ([0.6298253886699676, 0.030634798406724128]) \n",
      "Epoch 4700: D (5.376483386498876e-05 real_err, 6.389822374330834e-05 fake_err) G (6.389822374330834e-05 err); Real Dist ([3.9673798412680625, 1.1917158077900911]),  Fake Dist ([0.630826189994812, 0.030598536016729544]) \n",
      "Epoch 4800: D (5.2572679123841226e-05 real_err, 6.246761768124998e-05 fake_err) G (6.258683424675837e-05 err); Real Dist ([4.054582201957703, 1.2366043091055834]),  Fake Dist ([0.6336180248260498, 0.03157700180555526]) \n",
      "Epoch 4900: D (5.149974094820209e-05 real_err, 6.115623546065763e-05 fake_err) G (6.127545202616602e-05 err); Real Dist ([4.052155916571617, 1.252172263939718]),  Fake Dist ([0.6328649767637253, 0.03178937803644631]) \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Discriminator loop\n",
    "    for d_index in range(d_steps):\n",
    "        D.zero_grad()\n",
    "        \n",
    "        # Train D on real data\n",
    "        d_real_data = Variable(d_sampler(d_input_size))\n",
    "        d_real_decision = D(d_real_data)\n",
    "        d_real_error = cost(d_real_decision, Variable(torch.ones([1, 1])))\n",
    "        d_real_error.backward()\n",
    "        \n",
    "        # Train D on fake data\n",
    "        d_gen_input = Variable(g_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid G training with these data\n",
    "        d_fake_decision = D(d_fake_data.t())\n",
    "        d_fake_error = cost(d_fake_decision, Variable(torch.ones([1, 1])))\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step() # chages D's parameters based on backpropagation results\n",
    "        dre = extract(d_real_error)[0]\n",
    "        dfe = extract(d_fake_error)[0]\n",
    "        \n",
    "    # Generator loop\n",
    "    for g_index in range(g_steps):\n",
    "        G.zero_grad()\n",
    "        \n",
    "        gen_input = Variable(g_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(g_fake_data.t())\n",
    "        g_error = cost(dg_fake_decision, Variable(torch.ones([1, 1])))\n",
    "        \n",
    "        g_error.backward()\n",
    "        g_optimizer.step()\n",
    "        ge = extract(g_error.data)[0]\n",
    "        \n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"Epoch %s: D (%s real_err, %s fake_err) G (%s err); Real Dist (%s),  Fake Dist (%s) \" %\n",
    "             (epoch, dre, dfe, ge, stats(extract(d_real_data)), stats(extract(d_fake_data))))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
