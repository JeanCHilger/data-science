{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** This is a (poor) summary of the book \"Deep Learning\" by Ian Goodfellow Yoshua Bengio and Aaron Courville.\n",
    "Some parts were left blank whether because they were skipped or because they weren't read.\n",
    "Soon, this will be properly fixed, in the meantime this summary may be useful only for me.\n",
    "\n",
    "The texts inside curly braces represents action that must be performed when the whole summary is realy written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "{TODO}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1 INTRODUCTION</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2 LINEAR ALGEBRA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.1 SCALARS, VECTORS, MATRICES AND TENSORS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Scalar**: A single number.\n",
    "* **Vector**: Array of numbers. Each element is identified by an index.\n",
    "* **Matrix**: A 2-D array of numbers. Each element is identified by 2 indexes.\n",
    "* **Tensor**: A n-D array of numbers. Each element is identified by n indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.2 MULTIPLYING MATRICES AND VECTORS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.3 IDENTITY AND INVERSE MATRICES</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.4 LINEAR DEPENDENCE AND SPAN</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.5 NORMS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $L_p$ is defined by: $$\\|\\boldsymbol{x}\\|_p = \\left( \\sum_{i}|x_i|^p \\right)^\\frac{1}{p},$$ and mesures the distance from the origin to the point $\\boldsymbol{x}$.\n",
    "\n",
    "When $p=2$, it is called **Euclidean norm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.6 SPECIAL KINDS OF MATRICES AND VECTORS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"intro\">2.7 EIGENDECOMPOSITION</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decompose a matrix $\\boldsymbol{A}$ in **eigenvectors** and **eigenvalues**.\n",
    "\n",
    "* **Eigenvector**: vector $\\boldsymbol{v}$ whose multiplication by $\\boldsymbol{A}$ will only scale $\\boldsymbol{v}$: $$\\boldsymbol{Av} = \\lambda\\boldsymbol{v}$$\n",
    "* **Eigenvalue**: scalar $\\lambda$ that grants properties mentioned above to the corresponding eigenvector.\n",
    "\n",
    "$n$ linearly independent eigenvectors - $\\{v^{(1)}, ..., v^{(n)}\\}$ with eigenvalues $\\{\\lambda_1, ..., \\lambda_n\\}$ - can be concatenated in a matrix $\\boldsymbol{V} = [v^{(1)}, ..., v^{(n)}]$. Similarly, the eigenvalues can be concatenated in a vector $\\boldsymbol{\\lambda} = [\\lambda_1, ..., \\lambda_n]$. Thus, the eigendecomposition of $\\boldsymbol{A}$ is given by: $$\\boldsymbol{A}=\\boldsymbol{V}diag(\\boldsymbol{\\lambda})\\boldsymbol{V^{-1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.8 SINGULAR VALUE DECOMPOSITION (SVD)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decompose a matrix $\\boldsymbol{A}$ in **singular vectors** and **singular values**. The matrix will be written in the form $$\\boldsymbol{A} = \\boldsymbol{U}\\boldsymbol{D}\\boldsymbol{V}^T,$$ where:\n",
    "\n",
    "* $\\boldsymbol{U}$ is a orthogonal matrix whose columns are known as the **left-singular vectors**.\n",
    "* $\\boldsymbol{D}$ is a diagonal matrix. The elements along its diagonal are known as **singular values**.\n",
    "* $\\boldsymbol{V}$ is a orthogonal matrix whose columns are known as the **right-singular vectors**.\n",
    "\n",
    "(If $A_{m \\times n}$, then: $U_{m \\times m}$, $D_{m \\times n}$ and $V_{n \\times n}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.9 THE MOORE-PENROSE PSEUDOINVERSE</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pseudoinverse of $\\boldsymbol{A}$ is defined as a matrix $$\\boldsymbol{A}^+ = \\lim_{\\alpha \\to 0}\\left(\\boldsymbol{A}^T \\boldsymbol{A} + \\alpha \\boldsymbol{I} \\right)^{-1} \\boldsymbol{A}^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10 THE TRACE OPERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11 THE DETERMINANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The determinant is equal to the product of all eigenvalues of the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 PROBABILITY AND INFORMATION THEORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 WHY PROBABILITY?\n",
    "\n",
    "Machine learning deals with many uncertain variables...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 RANDOM VARIABLES\n",
    "\n",
    "A variable that may accept different values randomly. One of these values is called a **state**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 PROBABILITY DISTRIBUTIONS\n",
    "\n",
    "A **probability distribution** describes how a random variable is likely to assume each of its states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Discrete Variables and Probability Mass Functions\n",
    "\n",
    "A **Probability Mass Function** (PMF) is a function that maps the state of a discrete random variable to the probability of that state occurs.\n",
    "\n",
    "The probability of $x = x'$ is denoted by $P(x')$ (also may be $P(x=x')$).\n",
    "\n",
    "If $x=x'$ is impossible, then $P(x') = 0$. Likewise, if $x=x'$ is certain, then $P(x')=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Continuous Variables and Probability Density Functions\n",
    "\n",
    "A **Probability Density Function** (PDF) does not give a directly mapping between states and its probabilities..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Marginal Probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Expectation, Variance and Covariance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Machine Learning Basics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Learning Algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Capacity, Overfitting and Underfitting\n",
    "\n",
    "* **Generalization**: Ability to perform well on previously unseen data.\n",
    "\n",
    "The factors dertermining how well a machine learning algorithm performs are its ability to:\n",
    "\n",
    "1. Making the training error small.\n",
    "2. Making the gap between training and test error small.\n",
    "\n",
    "The first item, concerns to the problem of **underfitting**, that occurs when the error on training data is too large. The second has to do with the problem of **overfitting** which occurs when the error on training data is small, but the error on test data is large.\n",
    "\n",
    "Both overfitting and underfitting can be controlled by the model's **capacity**. Simply put, a model capacity tells how well a model can fit to a wide variety of functions. The capacity of a model can be controlled by choosing its **hypothesis space**: the set of functions that the algorithm is allowed to select as solution.\n",
    "\n",
    "### 5.2.1 The No Free Lunch Theorem\n",
    "\n",
    "The problems states that all machine learning algorithms has the same error for previously unobserved data, considering the average of all possible data-generating distributions. \n",
    "\n",
    "### 5.2.2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Hyperparameters and Validation Sets\n",
    "\n",
    "A **hyperparameter** is a setting that can be used to control the algorithm's behaviour. \n",
    "\n",
    "The **validation set** is a set sampled from the train set used to \"train\" (choose better) hyperparameters.\n",
    "\n",
    "### 5.3.1 Cross-Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Estimators, Bias and Variance\n",
    "\n",
    "### 5.4.1 Point  Estimation\n",
    "\n",
    "Point estimation is the attempt to provide the single best prediction for a quantity of interest (e.g. a parameter).\n",
    "\n",
    "### 5.4.2 Bias\n",
    "\n",
    "{Not understood}\n",
    "\n",
    "### 5.4.3 Variance and Standard Error\n",
    "\n",
    "### 5.4.4 Trading Off Bias and Variance to Minimize Mean Squared Error\n",
    "\n",
    "### 5.4.5 Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Bayesian Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Supervised Learning Algorithms\n",
    "\n",
    "### 5.7.1 Probabilistic Supervised Learning\n",
    "\n",
    "### 5.7.2 Support Vector Machines\n",
    "\n",
    "### 5.7.3 Other Simple Supervised Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Unsupervised Learning Algorithms\n",
    "\n",
    "A classic task for unsupervised learning is find the \"best\" **representation** for the data. Three main criteria for representation are:\n",
    "\n",
    "* Low-dimensional representation;\n",
    "* Sparse representation;\n",
    "* Independent representation;\n",
    "\n",
    "### 5.8.1 Principal Component Analysis\n",
    "\n",
    "### 5.8.2 k-means Clustering\n",
    "\n",
    "* Sort of one-hot enconding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 Stochastic Gradient Descent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.10 Building a Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.11 Challenges Motivating Deep Learning\n",
    "\n",
    "### 5.11.1 The Curse of Dimensionality\n",
    "\n",
    "The **curse of dimesionality** is the phenomenon that makes machine learning tasks extremely more difficult when the number of dimensions on the data increases.\n",
    "\n",
    "### 5.11.2 Local Constancy and Smoothness Regularization\n",
    "\n",
    "**Smoothness prior** or **local constancy prior** states that the function been learned should not change too much within a small region. This means that if we have a answer for $x$ that answer is probaly good for the neighborhood of $x$.\n",
    "\n",
    "### 5.11.3 Manifold Learning\n",
    "\n",
    "A **manifold** is a connected area. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Deep Feedforward Networks\n",
    "\n",
    "**Feedforward neural networks** are netowrks that pass the information only in the forward direction (no feedback)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Example: Learning XOR\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Gradient-Based Learning\n",
    "\n",
    "### 6.2.1 Cost Functions\n",
    "\n",
    "#### 6.2.1.1 Learning Conditional Distributions with Maximum Likelihood\n",
    "\n",
    "Most neural networks are trained using the maximum likelihood property, thus, the cost function for then is the cross-entropy loss function (the negative log-likelihood function).\n",
    "\n",
    "{Add more information}\n",
    "\n",
    "#### 6.2.1.2 Learning Conditional Statistics\n",
    "\n",
    "{Read Again}\n",
    "\n",
    "### 6.2.2 Output units\n",
    "\n",
    "The choice of the cost function is bounded to the choice of the output unit. As the cross-entropy is mostly used, the output unit determines it's form. Although any output unit may be used as hidden units, this sections focuses in their specific use in the output layer.\n",
    "\n",
    "#### 6.2.2.1 Linear Units for Gaussian Output Distributions\n",
    "\n",
    "Linear units provide a simple affine transformation. Given a input $\\boldsymbol{h}$, a **layer of linear output units** produce a vector $$\\hat{\\boldsymbol{y}} = \\boldsymbol{W}^T \\boldsymbol{h} + \\boldsymbol{b}$$. \n",
    "\n",
    "This units are often used to produce the mean a conditional Gaussian distribution.\n",
    "\n",
    "#### 6.2.2.2 Sigmoid Units for Bernoulli Output Distributions\n",
    "\n",
    "Some problems require the prediction of a binary variable $y$. To do so, one may use the Bernoulli distribution over $y$, conditioned to $\\boldsymbol{y}$.\n",
    "\n",
    "If using linear units (limitted to the interval $[0, 1]$), the gradient descent learning would not be effective. So, we may use another activation function, that lay in the interval $[0,1]$. Such a function is the sigmoid function, defined as $$\\sigma \\left( \\boldsymbol{w}^T \\boldsymbol{h} + \\boldsymbol{b} \\right),$$ where σ is the logistic sigmoid function.\n",
    "\n",
    "Its comom to use the representation $\\boldsymbol{z} = \\boldsymbol{w}^T \\boldsymbol{h} + \\boldsymbol{b}$ and $\\sigma \\left( \\boldsymbol{z} \\right)$.\n",
    "\n",
    "#### 6.2.2.3 Softmax Units for Multinoulli Output Distributions\n",
    "\n",
    "The softmax activation function can be used similarly as the sigmoid function, but instead of a two possible values (e.g. a two-class classifier) we are interested in $n$ possible values for the output.\n",
    "\n",
    "For this task, we need to produce a vector $\\hat{\\boldsymbol{y}}$ where $\\hat{y}_i = P \\left( y = i | \\boldsymbol{x} \\right)$. We also want that the whole vector sums to 1 and that each $\\hat{y}_i$ lies between $[0, 1]$.\n",
    "\n",
    "Again, first we use a linear transform to predict de unormalized propabilities: $\\boldsymbol{z} = \\boldsymbol{W}^T \\boldsymbol{h} + \\boldsymbol{b}$, where $z_i = \\log \\tilde{P} (y=i|\\boldsymbol{x})$. Then we can apply the softmax function defined by $$softmax(z)_i = \\frac{exp(z_i)}{\\sum_j exp(z_j)}$$\n",
    "\n",
    "\n",
    "#### 6.2.2.4 Other Output Types\n",
    "\n",
    "* Heteroscedastics models;\n",
    "* Mixture density networks;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Hidden Units\n",
    "\n",
    "The design of hidden units is a very active research area, however, the choosing process is not theoritical guided. The choice of a hidden unit may be accomplished by trial and error method, though an intuiton on each unit type may help.\n",
    "\n",
    "The next units presented accept an input vector $\\boldsymbol{x}$, then apply the affine transformation $\\boldsymbol{z} = \\boldsymbol{W}^T \\boldsymbol{x} + \\boldsymbol{b}$ which is evaluated by an activation function $g(\\boldsymbol{z})$.\n",
    "\n",
    "### 6.3.1 Rectified Linear Unit and Their Generalizations\n",
    "\n",
    "Rectified Linear Units or **ReLU** are defined by $$g(z_i) = max(0, z_i)$$\n",
    "\n",
    "Three generalizations of ReLU are based in the form $g(z_i) = max(0, z_i) + \\alpha_i min(0, z_i)$. \n",
    "\n",
    "The **absolute value retification** sets $\\alpha_i$ to $-1$, giving $g(z_i) = |z_i|$, the **leaky ReLU** sets $\\alpha_i$ to a small value like $0.01$ and the **parametric ReLU** sets $\\alpha_i$ as a learnable parameter.\n",
    "\n",
    "{maxout units}\n",
    "\n",
    "### 6.3.2 Logistic Sigmoid and Hyperbolic Tangent\n",
    "\n",
    "The sigmoidal function (already discussed) and the hyperbolic tanget are closed related, because $tanh(z) = 2\\sigma(2z) - 1$. Usually, when a sigmoidal activation function can be used, the hyperbolic tangent performs better.\n",
    "\n",
    "### 6.3.3 Other Hidden Units\n",
    "\n",
    "* Radial basis function (RBF): $h_i = \\exp \\left( -\\frac{1}{\\sigma^2} || \\boldsymbol{W}_{:,i} - \\boldsymbol{x} ||^2 \\right)$;\n",
    "* Softplus: $g(a) = \\zeta (a) = \\log \\left( 1 + e^a \\right)$;\n",
    "* Hard tanh: $g(a) = \\max(-1, \\min(1, a))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Architecture Desing\n",
    "\n",
    "The architecture of a neural network, refers to the amount of units used, how they connect to each other, the depth of the network and the width of the layers.\n",
    "\n",
    "### 6.4.1 Universal Approximation Properties and Depth\n",
    "\n",
    "A FNN is able to approximate any function, given sufficient hidden layers and as long as it has at least one hidden layer with \"squashing\" activation functions (see **universal approcimation theorem**).\n",
    "\n",
    "Is proven that a network with only a hidden layer may also represent any function, but at a cost of a very large width which make its use computationally infeasible.\n",
    "\n",
    "### 6.4.2 Other Architectural Considerations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Back-Propagation and Other Differentiation Algorithms\n",
    "\n",
    "### 6.5.1 Computational Graphs\n",
    "\n",
    "Here, computational representation of a graph is formalized:\n",
    "\n",
    "* Each node represents a variable (scalar, vector, matrix or another type);\n",
    "* An operation is defined as being a function of one or more variables;\n",
    "* And edge is drawn from $x$ to $y$ if $y$ is obtained as result of an operation on $x$.\n",
    "\n",
    "### 6.5.2 Chain Rule of Calculus\n",
    "\n",
    "Defines chain rule for a vector gradient and analogously to a tensor.\n",
    "\n",
    "{write the formulas}\n",
    "\n",
    "### 6.5.3 Recursively Applying the Chain Rule to Obtain Backprop\n",
    "\n",
    "The backprop is obtained by recursively computing chain rule\n",
    "\n",
    "{define it better}\n",
    "\n",
    "{show and explain algorithms}\n",
    "\n",
    "### 6.5.5 Symbol-to-Symbol Derivatives\n",
    "\n",
    "Some expression, such as graphs, are represented using variables whithout specific values which are called **symbols**. Some approaches to back-propagation accept as input a graph and a set of numerical values (to be applied on graph's symbols). This approach is called **symbol-to-number differentiation** and is used by libraries such as Torch and Caffe.\n",
    "\n",
    "Another approach is to generate another graph based on the input graph. This generated graph provide a symbolic representation of the desired derivatives. This approach is called **symbol-to-symbol differentiation** and is used by libraries such as TensorFlow.\n",
    "\n",
    "### 6.5.6 General Back-Propagation\n",
    "\n",
    "<h3 style=\"color:red\">SECTION SKIPPED AT THIS SECTION</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Regularization for Deep Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
